{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Neccessary Libraries\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_1</th>\n",
       "      <th>User_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ClickedNews</th>\n",
       "      <td>[NewsArticle_0, NewsArticle_1, NewsArticle_2, ...</td>\n",
       "      <td>[NewsArticle_1, NewsArticle_2, NewsArticle_3, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ClickedNewsID</th>\n",
       "      <td>[333, 145, 372, 194]</td>\n",
       "      <td>[187, 492, 445, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReadingTimes</th>\n",
       "      <td>[5, 12, 12, 8, 10]</td>\n",
       "      <td>[12, 14, 8, 6, 10]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ScrollBehavior</th>\n",
       "      <td>{'NewsArticle_0': {'20%': 3, '40%': 4, '60%': ...</td>\n",
       "      <td>{'NewsArticle_1': {'0%': 2, '20%': 3, '40%': 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SearchQueries</th>\n",
       "      <td>[tech, sports, sports]</td>\n",
       "      <td>[AI, politics, health]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LikedNewsID</th>\n",
       "      <td>[333, 194]</td>\n",
       "      <td>[492, 187]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SharedNewsID</th>\n",
       "      <td>[145, 333]</td>\n",
       "      <td>[187, 492, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CommentedNews</th>\n",
       "      <td>{'1': ['Comment 0'], '0': ['Comment 1', 'Comme...</td>\n",
       "      <td>{'187': ['Not great article!', 'Not very helpf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BookmarkedNews</th>\n",
       "      <td>[NewsArticle_4, NewsArticle_2]</td>\n",
       "      <td>[NewsArticle_2, NewsArticle_4]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DownloadedNews</th>\n",
       "      <td>[NewsArticle_3, NewsArticle_2]</td>\n",
       "      <td>[NewsArticle_1, NewsArticle_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ReadLaterList</th>\n",
       "      <td>[NewsArticle_1, NewsArticle_0]</td>\n",
       "      <td>[NewsArticle_0, NewsArticle_3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PreferredCategories</th>\n",
       "      <td>[Tech, Politics, Health]</td>\n",
       "      <td>[Tech, Politics, Health]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>InterestedTags</th>\n",
       "      <td>[AI, Climate Change, Economy, Sports]</td>\n",
       "      <td>[AI, Climate Change, Economy, Sports]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LanguagePreferences</th>\n",
       "      <td>[English, Spanish]</td>\n",
       "      <td>[English, Spanish]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserCountry</th>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UserAge</th>\n",
       "      <td>47</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArticleLengths</th>\n",
       "      <td>[572, 1166, 473, 727, 372]</td>\n",
       "      <td>[445, 1464, 1103, 1023, 1392]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArticleDates</th>\n",
       "      <td>[2024-12-08T12:01:26, 2024-11-27T12:01:26, 202...</td>\n",
       "      <td>[2024-11-26T12:01:26, 2024-12-19T12:01:26, 202...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArticleTimes</th>\n",
       "      <td>[night, evening, evening, morning, night]</td>\n",
       "      <td>[night, night, afternoon, morning, evening]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArticleSources</th>\n",
       "      <td>[CNN, BBC, The Verge, NY Times, The Guardian]</td>\n",
       "      <td>[CNN, BBC, The Verge, NY Times, The Guardian]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArticleAuthors</th>\n",
       "      <td>[Author1, Author2, Author3, Author4, Author5]</td>\n",
       "      <td>[Author1, Author2, Author3, Author4, Author5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ActivityTimes</th>\n",
       "      <td>[evening, evening, afternoon, morning, night]</td>\n",
       "      <td>[afternoon, evening, night, night, night]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EngagementFrequency</th>\n",
       "      <td>weekly</td>\n",
       "      <td>weekly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TrendingTopics</th>\n",
       "      <td>[AI, 2024 Elections, Global Warming, Cryptocur...</td>\n",
       "      <td>[AI, 2024 Elections, Global Warming, Cryptocur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RecencyScores</th>\n",
       "      <td>[0.189, 0.801, 0.9400000000000001, 0.385, 0.804]</td>\n",
       "      <td>[0.189, 0.801, 0.9400000000000001, 0.385, 0.804]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TopViewedNews</th>\n",
       "      <td>[NewsArticle_1, NewsArticle_2, NewsArticle_0, ...</td>\n",
       "      <td>[NewsArticle_1, NewsArticle_2, NewsArticle_0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TopSharedNews</th>\n",
       "      <td>[NewsArticle_1, NewsArticle_2, NewsArticle_0, ...</td>\n",
       "      <td>[NewsArticle_1, NewsArticle_2, NewsArticle_0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TopCommentedNews</th>\n",
       "      <td>[NewsArticle_1, NewsArticle_0, NewsArticle_2, ...</td>\n",
       "      <td>[NewsArticle_1, NewsArticle_0, NewsArticle_2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ArticlesRead</th>\n",
       "      <td>[NewsArticle_0, NewsArticle_1, NewsArticle_2, ...</td>\n",
       "      <td>[NewsArticle_0, NewsArticle_1, NewsArticle_2, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SkippedNews</th>\n",
       "      <td>[NewsArticle_2, NewsArticle_1]</td>\n",
       "      <td>[NewsArticle_2, NewsArticle_1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DislikedNews</th>\n",
       "      <td>[NewsArticle_2]</td>\n",
       "      <td>[NewsArticle_2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RelevanceScores</th>\n",
       "      <td>[0.893, 0.647, 0.633, 0.499, 0.811]</td>\n",
       "      <td>[0.893, 0.647, 0.633, 0.499, 0.811]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeviceType</th>\n",
       "      <td>tablet</td>\n",
       "      <td>tablet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LocationData</th>\n",
       "      <td>{'city': 'New York', 'coordinates': {'lat': 40...</td>\n",
       "      <td>{'city': 'New York', 'coordinates': {'lat': 40...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SessionDurations</th>\n",
       "      <td>[10, 9, 6, 16, 10]</td>\n",
       "      <td>[10, 9, 6, 16, 10]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                User_1  \\\n",
       "ClickedNews          [NewsArticle_0, NewsArticle_1, NewsArticle_2, ...   \n",
       "ClickedNewsID                                     [333, 145, 372, 194]   \n",
       "ReadingTimes                                        [5, 12, 12, 8, 10]   \n",
       "ScrollBehavior       {'NewsArticle_0': {'20%': 3, '40%': 4, '60%': ...   \n",
       "SearchQueries                                   [tech, sports, sports]   \n",
       "LikedNewsID                                                 [333, 194]   \n",
       "SharedNewsID                                                [145, 333]   \n",
       "CommentedNews        {'1': ['Comment 0'], '0': ['Comment 1', 'Comme...   \n",
       "BookmarkedNews                          [NewsArticle_4, NewsArticle_2]   \n",
       "DownloadedNews                          [NewsArticle_3, NewsArticle_2]   \n",
       "ReadLaterList                           [NewsArticle_1, NewsArticle_0]   \n",
       "PreferredCategories                           [Tech, Politics, Health]   \n",
       "InterestedTags                   [AI, Climate Change, Economy, Sports]   \n",
       "LanguagePreferences                                 [English, Spanish]   \n",
       "UserCountry                                                        USA   \n",
       "UserAge                                                             47   \n",
       "ArticleLengths                              [572, 1166, 473, 727, 372]   \n",
       "ArticleDates         [2024-12-08T12:01:26, 2024-11-27T12:01:26, 202...   \n",
       "ArticleTimes                 [night, evening, evening, morning, night]   \n",
       "ArticleSources           [CNN, BBC, The Verge, NY Times, The Guardian]   \n",
       "ArticleAuthors           [Author1, Author2, Author3, Author4, Author5]   \n",
       "ActivityTimes            [evening, evening, afternoon, morning, night]   \n",
       "EngagementFrequency                                             weekly   \n",
       "TrendingTopics       [AI, 2024 Elections, Global Warming, Cryptocur...   \n",
       "RecencyScores         [0.189, 0.801, 0.9400000000000001, 0.385, 0.804]   \n",
       "TopViewedNews        [NewsArticle_1, NewsArticle_2, NewsArticle_0, ...   \n",
       "TopSharedNews        [NewsArticle_1, NewsArticle_2, NewsArticle_0, ...   \n",
       "TopCommentedNews     [NewsArticle_1, NewsArticle_0, NewsArticle_2, ...   \n",
       "ArticlesRead         [NewsArticle_0, NewsArticle_1, NewsArticle_2, ...   \n",
       "SkippedNews                             [NewsArticle_2, NewsArticle_1]   \n",
       "DislikedNews                                           [NewsArticle_2]   \n",
       "RelevanceScores                    [0.893, 0.647, 0.633, 0.499, 0.811]   \n",
       "DeviceType                                                      tablet   \n",
       "LocationData         {'city': 'New York', 'coordinates': {'lat': 40...   \n",
       "SessionDurations                                    [10, 9, 6, 16, 10]   \n",
       "\n",
       "                                                                User_2  \n",
       "ClickedNews          [NewsArticle_1, NewsArticle_2, NewsArticle_3, ...  \n",
       "ClickedNewsID                                       [187, 492, 445, 5]  \n",
       "ReadingTimes                                        [12, 14, 8, 6, 10]  \n",
       "ScrollBehavior       {'NewsArticle_1': {'0%': 2, '20%': 3, '40%': 1...  \n",
       "SearchQueries                                   [AI, politics, health]  \n",
       "LikedNewsID                                                 [492, 187]  \n",
       "SharedNewsID                                             [187, 492, 5]  \n",
       "CommentedNews        {'187': ['Not great article!', 'Not very helpf...  \n",
       "BookmarkedNews                          [NewsArticle_2, NewsArticle_4]  \n",
       "DownloadedNews                          [NewsArticle_1, NewsArticle_3]  \n",
       "ReadLaterList                           [NewsArticle_0, NewsArticle_3]  \n",
       "PreferredCategories                           [Tech, Politics, Health]  \n",
       "InterestedTags                   [AI, Climate Change, Economy, Sports]  \n",
       "LanguagePreferences                                 [English, Spanish]  \n",
       "UserCountry                                                        USA  \n",
       "UserAge                                                             41  \n",
       "ArticleLengths                           [445, 1464, 1103, 1023, 1392]  \n",
       "ArticleDates         [2024-11-26T12:01:26, 2024-12-19T12:01:26, 202...  \n",
       "ArticleTimes               [night, night, afternoon, morning, evening]  \n",
       "ArticleSources           [CNN, BBC, The Verge, NY Times, The Guardian]  \n",
       "ArticleAuthors           [Author1, Author2, Author3, Author4, Author5]  \n",
       "ActivityTimes                [afternoon, evening, night, night, night]  \n",
       "EngagementFrequency                                             weekly  \n",
       "TrendingTopics       [AI, 2024 Elections, Global Warming, Cryptocur...  \n",
       "RecencyScores         [0.189, 0.801, 0.9400000000000001, 0.385, 0.804]  \n",
       "TopViewedNews        [NewsArticle_1, NewsArticle_2, NewsArticle_0, ...  \n",
       "TopSharedNews        [NewsArticle_1, NewsArticle_2, NewsArticle_0, ...  \n",
       "TopCommentedNews     [NewsArticle_1, NewsArticle_0, NewsArticle_2, ...  \n",
       "ArticlesRead         [NewsArticle_0, NewsArticle_1, NewsArticle_2, ...  \n",
       "SkippedNews                             [NewsArticle_2, NewsArticle_1]  \n",
       "DislikedNews                                           [NewsArticle_2]  \n",
       "RelevanceScores                    [0.893, 0.647, 0.633, 0.499, 0.811]  \n",
       "DeviceType                                                      tablet  \n",
       "LocationData         {'city': 'New York', 'coordinates': {'lat': 40...  \n",
       "SessionDurations                                    [10, 9, 6, 16, 10]  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampleData = pd.read_json('./SampleUserData.json')\n",
    "sampleData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "### Proximity News Data Hyperparameters\n",
    "MaxNewsID = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProxiNewsAI_Dataset(Dataset):\n",
    "    def __init__(self, data, MaxNewsID):\n",
    "        self.data = data\n",
    "        self.MaxNewsID = MaxNewsID\n",
    "    \n",
    "    def getUsers(self):\n",
    "        return self.data.columns.tolist()\n",
    "    \n",
    "    #TODO: Instead of using List as the Data we need to use PyTorch Tensors.\n",
    "    #TODO: We need to Normalize the Data with other techniques.\n",
    "\n",
    "    def ClickedNewsNormalization(self, userID):\n",
    "        clickedNews = self.data[userID]['ClickedNewsID']\n",
    "\n",
    "        return [i/self.MaxNewsID for i in clickedNews]\n",
    "    \n",
    "    #TODO: Instead of using List as the Data we need to use PyTorch Tensors.\n",
    "    #TODO: We need to Normalize the Data with other techniques.\n",
    "\n",
    "    def ReadingTimesNormalization(self, userID):\n",
    "        readingTimes = self.data[userID]['ReadingTimes']\n",
    "\n",
    "        return [i/100 for i in readingTimes]\n",
    "    \n",
    "    #TODO: Instead of using List as the Data we need to use PyTorch Tensors.\n",
    "    #TODO: We need to Normalize the Data with other techniques.\n",
    "\n",
    "    def ScrollBehaviorNormalization(self, userID):\n",
    "        norm = []\n",
    "        scrollBehavior = self.data[userID]['ScrollBehavior']\n",
    "        for NewsArticle in scrollBehavior.keys():\n",
    "\n",
    "            # ['20%', '40%', '60%', '80%', '100%']\n",
    "            scrolls = list(scrollBehavior[NewsArticle].values())\n",
    "            \n",
    "            # Normalization\n",
    "            norm.append([i/100 for i in scrolls])\n",
    "        \n",
    "        return norm\n",
    "\n",
    "    #TODO: Need to implement tokenizer for this function\n",
    "\n",
    "    def SearchQueriesTokenization(self, userID):\n",
    "        SearchQueries = self.data[userID]['SearchQueries']\n",
    "        return SearchQueries\n",
    "    \n",
    "    #TODO: Instead of using List as the Data we need to use PyTorch Tensors.\n",
    "    #TODO: We need to Normalize the Data with other techniques.\n",
    "\n",
    "    def LikedNewsNormalization(self, userID):\n",
    "        LikedNews = self.data[userID]['LikedNewsID']\n",
    "\n",
    "        return [i/self.MaxNewsID for i in LikedNews]\n",
    "    \n",
    "    #TODO: Instead of using List as the Data we need to use PyTorch Tensors.\n",
    "    #TODO: We need to Normalize the Data with other techniques.\n",
    "\n",
    "    def SharedNewsNormalization(self, userID):\n",
    "        SharedNews = self.data[userID]['SharedNewsID']\n",
    "\n",
    "        return [i/self.MaxNewsID for i in SharedNews]\n",
    "    \n",
    "\n",
    "    def CommentedNewsEncoding(self, userID, newsTitles):\n",
    "        CommentedNews = self.data[userID]['CommentedNews']\n",
    "        prompt_template = f\"\"\"Here is News Articles With the comments from the User {userID}\"\"\"\n",
    "        for NewsArticle in CommentedNews.keys():\n",
    "            \n",
    "            prompt_template += f\"\"\"\\n{newsTitles[int(NewsArticle)]}\\n\"\"\"\n",
    "    \n",
    "            for idx, comment in enumerate(CommentedNews[NewsArticle]):\n",
    "                prompt_template += f\"\"\"Comment_{idx}: {comment}\\n\"\"\"\n",
    "        \n",
    "        print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: User_1\n",
      "          \n",
      "          Clicked News Normalized: [0.666, 0.29, 0.744, 0.388].\n",
      "          Reading Time Normalized: [0.05, 0.12, 0.12, 0.08, 0.1].\n",
      "          Scrolling Time data of user: [[0.03, 0.04, 0.05, 0.0, 0.05], [0.04, 0.0, 0.05, 0.0, 0.02], [0.01, 0.04, 0.01, 0.02, 0.01], [0.05, 0.02, 0.01, 0.05, 0.05], [0.02, 0.03, 0.0, 0.0, 0.02]].\n",
      "          Search Queries tokens: ['tech', 'sports', 'sports'].\n",
      "          Liked News Normalization: [0.666, 0.388].\n",
      "          Shared News Normalization: [0.29, 0.666].\n",
      "          \n",
      "User: User_2\n",
      "          \n",
      "          Clicked News Normalized: [0.374, 0.984, 0.89, 0.01].\n",
      "          Reading Time Normalized: [0.12, 0.14, 0.08, 0.06, 0.1].\n",
      "          Scrolling Time data of user: [[0.02, 0.03, 0.01, 0.04, 0.05, 0.02], [0.0, 0.02, 0.03, 0.0, 0.01, 0.01], [0.03, 0.05, 0.04, 0.02, 0.0, 0.05], [0.01, 0.0, 0.03, 0.04, 0.01, 0.0], [0.02, 0.04, 0.05, 0.01, 0.03, 0.04]].\n",
      "          Search Queries tokens: ['AI', 'politics', 'health'].\n",
      "          Liked News Normalization: [0.984, 0.374].\n",
      "          Shared News Normalization: [0.374, 0.984, 0.01].\n",
      "          \n"
     ]
    }
   ],
   "source": [
    "dataset = ProxiNewsAI_Dataset(sampleData, MaxNewsID)\n",
    "\n",
    "for user in dataset.getUsers():\n",
    "    CNN = dataset.ClickedNewsNormalization(user)\n",
    "    RTN = dataset.ReadingTimesNormalization(user)\n",
    "    SBN = dataset.ScrollBehaviorNormalization(user)\n",
    "    SQT = dataset.SearchQueriesTokenization(user)\n",
    "    LNN = dataset.LikedNewsNormalization(user)\n",
    "    SNN = dataset.SharedNewsNormalization(user)\n",
    "\n",
    "    print(f'''User: {user}\n",
    "          \n",
    "          Clicked News Normalized: {CNN}.\n",
    "          Reading Time Normalized: {RTN}.\n",
    "          Scrolling Time data of user: {SBN}.\n",
    "          Search Queries tokens: {SQT}.\n",
    "          Liked News Normalization: {LNN}.\n",
    "          Shared News Normalization: {SNN}.\n",
    "          ''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is News Articles With the comments from the User User_1\n",
      "Global Climate Crisis: UN Warns of Rising Sea Levels by 2050\n",
      "\n",
      "Comment_0: Comment 0\n",
      "\n",
      "Artificial Intelligence Advances: ChatGPT Leads the Way in Language Processing\n",
      "\n",
      "Comment_0: Comment 1\n",
      "\n",
      "Comment_1: Comment 2\n",
      "\n",
      "Tech Innovations 2025: Quantum Computing Edges Closer to Mainstream\n",
      "\n",
      "Comment_0: Comment 2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "news_headlines = [\n",
    "    \"Artificial Intelligence Advances: ChatGPT Leads the Way in Language Processing\",\n",
    "    \"Global Climate Crisis: UN Warns of Rising Sea Levels by 2050\",\n",
    "    \"Tech Innovations 2025: Quantum Computing Edges Closer to Mainstream\"\n",
    "]\n",
    "\n",
    "dataset.CommentedNewsEncoding('User_1', news_headlines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
